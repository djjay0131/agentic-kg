"""
Tests for agentic_kg.agents.continuation.

Generated by test-generator agent.
"""

from types import SimpleNamespace
from unittest.mock import MagicMock

import pytest

from agentic_kg.agents.continuation import ContinuationAgent
from agentic_kg.agents.schemas import ContinuationProposal, WorkflowStatus
from agentic_kg.agents.state import create_initial_state


class TestContinuationAgent:
    """Tests for ContinuationAgent."""

    @pytest.fixture
    def agent(self, mock_llm, mock_repo, mock_search, mock_relations):
        return ContinuationAgent(
            llm_client=mock_llm,
            repository=mock_repo,
            search_service=mock_search,
            relation_service=mock_relations,
        )

    @pytest.fixture
    def llm_proposal(self):
        return ContinuationProposal(
            problem_id="prob-1",
            title="Scalable GNN Approach",
            methodology="Apply subgraph sampling with learned importance weights.",
            expected_outcome="2x speedup with minimal accuracy loss",
            confidence=0.7,
        )

    def test_name(self, agent):
        assert agent.name == "continuation"

    @pytest.mark.asyncio
    async def test_run_happy_path(self, agent, mock_llm, llm_proposal, state_with_selected_problem):
        """Run generates a proposal for the selected problem."""
        mock_llm.structured_extract.return_value = SimpleNamespace(content=llm_proposal)

        result = await agent.run(state_with_selected_problem)

        assert result["proposal"] is not None
        assert result["proposal"]["title"] == "Scalable GNN Approach"
        assert result["proposal_approved"] is False

    @pytest.mark.asyncio
    async def test_run_no_problem_selected(self, agent, initial_state):
        """Run returns error when no problem is selected."""
        result = await agent.run(initial_state)

        assert "No problem selected" in result["errors"][-1]

    @pytest.mark.asyncio
    async def test_run_handles_repo_error(self, agent, mock_repo, state_with_selected_problem):
        """Run handles repository errors gracefully."""
        mock_repo.get_problem.side_effect = RuntimeError("DB down")

        result = await agent.run(state_with_selected_problem)

        assert any("DB down" in e for e in result["errors"])

    @pytest.mark.asyncio
    async def test_run_sets_problem_id_if_missing(
        self, agent, mock_llm, state_with_selected_problem
    ):
        """If LLM returns proposal without problem_id, it is set from context."""
        proposal_no_id = ContinuationProposal(
            problem_id="",
            title="Some Proposal Title",
            methodology="A methodology that is long enough to pass validation.",
            expected_outcome="Expected outcome text",
        )
        mock_llm.structured_extract.return_value = SimpleNamespace(content=proposal_no_id)

        result = await agent.run(state_with_selected_problem)

        assert result["proposal"]["problem_id"] == "prob-1"

    @pytest.mark.asyncio
    async def test_run_loads_related_problems(
        self, agent, mock_llm, mock_relations, state_with_selected_problem, llm_proposal
    ):
        """Related problems are loaded from relation service."""
        mock_llm.structured_extract.return_value = SimpleNamespace(content=llm_proposal)

        await agent.run(state_with_selected_problem)

        mock_relations.get_related_problems.assert_called_once()

    @pytest.mark.asyncio
    async def test_run_without_relations_service(self, mock_llm, mock_repo, llm_proposal):
        """Works when relation service is None."""
        agent = ContinuationAgent(
            llm_client=mock_llm,
            repository=mock_repo,
            search_service=None,
            relation_service=None,
        )
        mock_llm.structured_extract.return_value = SimpleNamespace(content=llm_proposal)
        state = create_initial_state()
        state = {**state, "selected_problem_id": "prob-1"}

        result = await agent.run(state)

        assert result["proposal"] is not None
